{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Urban Sound Classification**\n",
        "\n",
        "This notebook includes the preprocessing steps for Urban Sound Dataset as a part of Koç Holding Deep Learning Bootcamp."
      ],
      "metadata": {
        "id": "ZVfwDuxOB4tA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "N6x8H3AbCtrR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NFQlj7A71KqK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accessing the drive and spectograms of the sounds.**"
      ],
      "metadata": {
        "id": "DNe0FKBvCztn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifiXCw5pveWL",
        "outputId": "7a6577e2-47e4-442e-9c80-4ecf0d8082f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "path='/content/drive/MyDrive/spectrograms/'\n",
        "\n",
        "def get_filepaths(directory):\n",
        "    \"\"\"\n",
        "    This function will generate the file names in a directory \n",
        "    tree by walking the tree top-down. And will return the directories\n",
        "    and their label as a list.\n",
        "    \"\"\"\n",
        "    file_paths = []  # List which will store all of the full filepaths.\n",
        "\n",
        "    # Walk the tree.\n",
        "    for root, directories, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            # Join the two strings in order to form the full filepath.\n",
        "            filepath = os.path.join(root, filename)\n",
        "            dirname=os.path.basename(root)\n",
        "            file_paths.append([filepath,int(dirname)]) \n",
        "\n",
        "    return file_paths  # Self-explanatory.\n",
        "\n",
        "# Run the above function and store its results in a variable.   \n",
        "full_file_paths = get_filepaths(path)"
      ],
      "metadata": {
        "id": "o7LPPV168LDI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is 8732 sound spectrograms in this dataset."
      ],
      "metadata": {
        "id": "0rjoEclQDhrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(full_file_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MicXNiXl1Y8R",
        "outputId": "07eb0be3-7345-4f70-d7ac-bb0c3b9aa08d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8732"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_file_paths[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzMC2HML8h4m",
        "outputId": "894d4d2a-b041-4b28-f257-e72f8649058f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/drive/MyDrive/spectrograms/6/102305-6-0-0.png', 6],\n",
              " ['/content/drive/MyDrive/spectrograms/6/106955-6-0-0.png', 6],\n",
              " ['/content/drive/MyDrive/spectrograms/6/110622-6-0-0.png', 6],\n",
              " ['/content/drive/MyDrive/spectrograms/6/111048-6-0-0.png', 6],\n",
              " ['/content/drive/MyDrive/spectrograms/6/122690-6-0-0.png', 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "56cCtIFHD1AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Created empty list of arrays for images and their classes\n",
        "images, cls = [],[]\n",
        "# Iterate full_file_paths \n",
        "for i in tqdm(range(len(full_file_paths))):\n",
        "  new=full_file_paths[i][0]                # Directory of the image\n",
        "  dir=full_file_paths[i][1]                # Class of the image\n",
        "\n",
        "  # Read the image\n",
        "  img = np.asarray(Image.open(new))\n",
        "  \n",
        "  # Resize (128,128)        \n",
        "  img_r= cv.resize(img,[128,128])\n",
        "\n",
        "  # Convert to grayscale\n",
        "  img_g = cv.cvtColor(img_r, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Normalize the image in [0, 1] range\n",
        "  img=cv.normalize(img_g,None,0,1,cv.NORM_MINMAX)\n",
        "  #if i == 0:\n",
        "  images.append(img.copy())\n",
        "  cls.append(dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tneNHpiS24R6",
        "outputId": "ace9c0d1-9fe0-414d-aebd-0f0a09437edd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8732/8732 [22:18<00:00,  6.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(images).shape , np.array(cls).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C1vD2IbmiNa",
        "outputId": "fbdd7f4f-304d-451c-e30a-4076cb2254a5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8732, 128, 128), (8732,))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train - Validation - Test Split**"
      ],
      "metadata": {
        "id": "zEXjyV_v-Sjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, cls, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "6niQBGH_VFVf"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(y_train), len(X_val), len(y_val), len(X_test), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T-Z51KQ4IcB",
        "outputId": "d4e79819-79cc-4cf3-ec53-2dbc1b066e25"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5238, 5238, 1747, 1747, 1747, 1747)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the Data**"
      ],
      "metadata": {
        "id": "qhTi14if-XvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data\n",
        "np.save('/content/drive/MyDrive/metadata/X_train_dataframe', np.array(X_train))\n",
        "\n",
        "np.save('/content/drive/MyDrive/metadata/y_train_dataframe', np.array(y_train))\n",
        "\n",
        "np.save('/content/drive/MyDrive/metadata/X_test_dataframe', np.array(X_test))\n",
        "\n",
        "np.save('/content/drive/MyDrive/metadata/y_test_dataframe', np.array(y_test))\n",
        "\n",
        "np.save('/content/drive/MyDrive/metadata/X_val_dataframe', np.array(X_val))\n",
        "\n",
        "np.save('/content/drive/MyDrive/metadata/y_val_dataframe', np.array(y_val))\n"
      ],
      "metadata": {
        "id": "91BHjfCnBdTy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKKzQK1i9nk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}